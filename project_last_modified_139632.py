# -*- coding: utf-8 -*-
"""Project_Last_Modified_139632.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p7EjSSGe6nYcHp-4ROuasBJQzGodjwS1

# Facial Emotion Recognition Analysis Using FER-2013 Dataset

## Import Libraries
"""

!pip install pillow

!pip install tensorflow

from google.colab import drive
import os
import random
import shutil
import cv2
import albumentations as A
import tensorflow as tf
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import seaborn as sns
from sklearn.metrics import mutual_info_score
from sklearn.metrics import silhouette_score, silhouette_samples
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, PReLU, Add, UpSampling2D, LeakyReLU, Flatten, Dense, Lambda
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import *

"""## Load Data"""

drive.mount('/content/drive')

images_dir= '/content/drive/MyDrive/Data_Visualization/Course_Project/images/'

"""## Exploratory Data Analysis (EDA)

### Explore Labels/ Class Names
"""

classes=os.listdir(images_dir)
count_classes=len(classes)
classes

"""### Count Total Number of Images & Images at Each Class"""

def count_images(images_dir):
  total=0
  dict={}
  for directory in os.listdir(images_dir):
    c_total=len(os.listdir(images_dir+directory))
    dict[directory]=c_total
    total=total+c_total
  return total, dict

total_images,number_of_images_dict=count_images(images_dir)
print(f'Total Images: {total_images}')
print(f'Number of Images in each Class: {number_of_images_dict}')

"""### Feature Extraction"""

import pandas as pd

def extract_features_to_dataframe(images_dir):

    features = []

    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)

        if not os.path.isdir(class_path):
            continue

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)

            try:

                img = Image.open(img_path).convert('L')
                img_array = np.array(img)

                feature_dict = {
                    "Class": class_name,
                    "Image_Name": img_name,
                    "Width": img.size[0],
                    "Height": img.size[1],
                    "Mean_Pixel_Intensity": np.mean(img_array),
                    "Std_Pixel_Intensity": np.std(img_array),
                }

                features.append(feature_dict)

            except Exception as e:
                print(f"Error processing {img_name}: {e}")
                continue

    df = pd.DataFrame(features)

    return df

images_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/images/'
features_df = extract_features_to_dataframe(images_dir)

# Save the DataFrame to a CSV file
# features_df.to_csv("image_features.csv", index=False)

features_df.head()

"""### Class Balancing Test (Checking)"""

def plot_bar_image_at_each_class(images_dir):
    class_counts = {}

    # Count images in each class
    classes = os.listdir(images_dir)
    for class_name in classes:
        class_path = os.path.join(images_dir, class_name)
        if os.path.isdir(class_path):
            class_counts[class_name] = len(os.listdir(class_path))

    # Sort class_counts by count descending
    sorted_class_counts = dict(sorted(class_counts.items(), key=lambda item: item[1], reverse=True))

    classes = list(sorted_class_counts.keys())
    counts = list(sorted_class_counts.values())

    plt.figure(figsize=(8,6))
    bars = plt.bar(classes, counts, color="#34495e")

    for bar, count in zip(bars, counts):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),
                 ha='center', va='bottom')

    plt.xlabel('Classes')
    plt.ylabel('Number of Images')
    plt.title('Number of Images per Class')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

plot_bar_image_at_each_class(images_dir)

def imbalanced_ratio(image_count_dict):
  max_count_class=max(image_count_dict.values())
  min_count_class=min(image_count_dict.values())
  ratio=max_count_class/min_count_class
  return ratio

imbalanced_ratio=imbalanced_ratio(number_of_images_dict)
print(f"Imbalanced Ratio= {imbalanced_ratio:.2f}")

"""### Pixel Intensity Analysis"""

def compute_pixel_intensity_stats(images_dir):
    intensity_stats = []

    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        if not os.path.isdir(class_path):
            continue

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            try:
                img = Image.open(img_path).convert('L')
                img_array = np.array(img)
                mean_intensity = np.mean(img_array)
                std_intensity = np.std(img_array)

                intensity_stats.append({
                    "Class": class_name,
                    "Image": img_name,
                    "Mean_Pixel_Intensity": mean_intensity,
                    "STD_Pixel_Intensity": std_intensity
                })

            except Exception as e:
                print(f"Error processing {img_name}: {e}")
                continue

    df_stats = pd.DataFrame(intensity_stats)
    return df_stats

df_stats = compute_pixel_intensity_stats(images_dir)

df_stats

# Plot Histogram

def pixel_intensity_analysis_per_class(images_dir, classes):
    num_classes = len(classes)
    cols = 3
    rows = (num_classes + cols - 1) // cols

    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))
    axes = axes.flatten()
    for idx, class_name in enumerate(classes):
        pixel_intensities = []
        class_path = os.path.join(images_dir, class_name)
        class_images = os.listdir(class_path)

        for img_name in class_images:
            img_path = os.path.join(class_path, img_name)
            img = Image.open(img_path).convert('L')
            img_array = np.array(img)
            pixel_intensities.extend(img_array.flatten())

        sns.histplot(pixel_intensities, bins=256, kde=True, ax=axes[idx])
        axes[idx].set_xlabel('Pixel Intensity')
        axes[idx].set_ylabel('Frequency')
        axes[idx].set_title(f'Class: {class_name}')

    # Hide any empty subplots
    for i in range(idx + 1, len(axes)):
        fig.delaxes(axes[i])

    plt.tight_layout()
    plt.show()

pixel_intensity_analysis_per_class(images_dir, classes)

"""### Compute Mutual Information Between Two Images ( Check the Relationship)"""

def load_random_image_from_class(class_name):
    class_path = os.path.join(images_dir, class_name)
    image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png')]
    random_file = random.choice(image_files)
    img_path = os.path.join(class_path, random_file)
    img = Image.open(img_path).convert('L')
    img = np.array(img)
    return img, random_file

class_folders = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]

def calculate_mutual_information(img1, img2):
    img1_flat = img1.flatten()
    img2_flat = img2.flatten()
    mi = mutual_info_score(img1_flat, img2_flat)
    return mi

# Show sample of images with Mutual Information

def show_image_pairs_with_mi(num_pairs=5):
    fig, axarr = plt.subplots(num_pairs, 3, figsize=(6, num_pairs * 2.5))

    for idx in range(num_pairs):
        class1 = random.choice(class_folders)
        class2 = random.choice(class_folders)

        img1, _ = load_random_image_from_class(class1)
        img2, _ = load_random_image_from_class(class2)
        mi_value = calculate_mutual_information(img1, img2)

        # Left image
        axarr[idx, 0].imshow(img1, cmap='gray')
        axarr[idx, 0].set_title(f'{class1}', fontsize=10)
        axarr[idx, 0].axis('off')

        # Arrow with MI score above it
        axarr[idx, 1].text(0.5, 0.7, 'MI: {:.4f}'.format(mi_value), fontsize=10, ha='center', va='center')
        axarr[idx, 1].text(0.5, 0.3, 'â†’', fontsize=20, ha='center', va='center')
        axarr[idx, 1].axis('off')

        # Right image
        axarr[idx, 2].imshow(img2, cmap='gray')
        axarr[idx, 2].set_title(f'{class2}', fontsize=10)
        axarr[idx, 2].axis('off')

    plt.tight_layout(h_pad=3.0)
    plt.show()

show_image_pairs_with_mi(num_pairs=5)

"""## Data Pre-Processing

### Remove Outliers
"""

def remove_outliers(images_dir, image_size=(48, 48), iqr_multiplier=1.0, preview=False):
    for class_name in os.listdir(images_dir):
        class_dir = os.path.join(images_dir, class_name)
        if not os.path.isdir(class_dir):
            continue

        print(f"\nClass: {class_name}")
        stds = []
        image_paths = []

        # Step 1: Compute standard deviation per image
        for img_name in os.listdir(class_dir):
            if not img_name.lower().endswith(('jpg', 'jpeg', 'png')):
                continue
            img_path = os.path.join(class_dir, img_name)
            try:
                img = Image.open(img_path).convert('L').resize(image_size)
                pixel_array = np.array(img)
                std_val = pixel_array.std()
                stds.append(std_val)
                image_paths.append(img_path)
            except Exception as e:
                print(f"Error loading image {img_name}: {e}")
                continue

        if len(stds) == 0:
            print("No valid images found.")
            continue

        stds = np.array(stds)

        # Step 2: Compute IQR bounds
        Q1 = np.percentile(stds, 25)
        Q3 = np.percentile(stds, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - iqr_multiplier * IQR
        upper_bound = Q3 + iqr_multiplier * IQR

        print(f"IQR bounds (std): {lower_bound:.2f} to {upper_bound:.2f}")

        # Step 3: Identify and optionally preview outliers
        outliers = [(p, s) for p, s in zip(image_paths, stds) if s < lower_bound or s > upper_bound]
        print(f"Identified {len(outliers)} outlier(s).")

        if preview and outliers:
            fig, axes = plt.subplots(1, min(5, len(outliers)), figsize=(15, 3))
            for ax, (path, std_val) in zip(axes, outliers[:5]):
                img = Image.open(path).convert('L')
                ax.imshow(img, cmap='gray')
                ax.set_title(f"Std: {std_val:.2f}")
                ax.axis('off')
            plt.show()

        # Step 4: Delete outliers
        removed_count = 0
        for img_path, _ in outliers:
            try:
                os.remove(img_path)
                removed_count += 1
            except Exception as e:
                print(f"Failed to remove {img_path}: {e}")

        print(f"Removed {removed_count} outlier image(s) from '{class_name}'.")
    return images_dir

original_images_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/images/'

augmented_output_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/augmented_images/'

"""### Remove the Noise"""

def reset_directory(path):
    if os.path.exists(path):
        shutil.rmtree(path)
    os.makedirs(path, exist_ok=True)

def denoise_images(images_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Apply Non-Local Means Denoising
            denoised_img = cv2.fastNlMeansDenoising(img, None, h=10, templateWindowSize=7, searchWindowSize=21)

            # Save the denoised image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, denoised_img)

"""### Remove Blur on Images"""

def sharpen_images(images_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Apply Gaussian blur
            blurred = cv2.GaussianBlur(img, (5, 5), 0)

            # Apply Unsharp Masking
            sharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)

            # Save the sharpened image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, sharpened)

"""### Improve Resolution"""

def upscale_images(images_dir, output_dir, scale=2):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Upscale image using bicubic interpolation
            height, width = img.shape
            upscaled = cv2.resize(img, (width * scale, height * scale), interpolation=cv2.INTER_CUBIC)

            # Save the upscaled image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, upscaled)

"""### Full Image Preprocessing"""

def full_image_preprocessing_pipeline(original_dir, base_output_dir, image_size=(48, 48), scale=2, iqr_multiplier=1.5, preview_outliers=False):
    # Step 0: Clean output folder
    reset_directory(base_output_dir)

    # Step 1: Create 'cleaned' directory to work in
    print("\nStep 1: Removing outliers...")
    cleaned_dir = os.path.join(base_output_dir, 'cleaned')
    shutil.copytree(original_dir, cleaned_dir, dirs_exist_ok=True)
    remove_outliers(cleaned_dir, image_size=image_size, iqr_multiplier=iqr_multiplier, preview=preview_outliers)

    # Step 2: Denoising images in-place
    print("\nStep 2: Denoising images...")
    denoise_images(cleaned_dir, cleaned_dir)

    # Step 3: Sharpening images in-place
    print("\nStep 3: Sharpening images...")
    sharpen_images(cleaned_dir, cleaned_dir)

    # Step 4: Upscaling images â†’ write to final_output (not base_output_dir!)
    print("\nStep 4: Upscaling images...")
    final_output_dir = os.path.join(base_output_dir, 'final_output')
    reset_directory(final_output_dir)
    upscale_images(cleaned_dir, final_output_dir, scale=scale)

    print(f"\nâœ… Preprocessing completed. Final output saved in: {final_output_dir}")
    return final_output_dir

output_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessed_images'

full_image_preprocessing_pipeline(
    original_dir=original_images_dir,
    base_output_dir=output_dir,
    image_size=(48, 48),
    scale=2,
    iqr_multiplier=1.5,
    preview_outliers=True
)

"""### Combining Preprocessing

### Data Augmentation
"""

def augmented_images(preprocessed_dir, output_dir, target_count_per_class):

    reset_directory(output_dir)

    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Rotate(limit=15, p=0.5),
        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),
        A.GaussNoise(p=0.2),
    ])

    for class_name in os.listdir(preprocessed_dir):
        # âœ… Skip intermediate or non-class folders
        if class_name.lower() in ['cleaned', '.ds_store']:
            print(f"Skipping non-class folder: {class_name}")
            continue

        class_input_path = os.path.join(preprocessed_dir, class_name)
        if not os.path.isdir(class_input_path):
            continue

        class_output_path = os.path.join(output_dir, class_name)
        reset_directory(class_output_path)

        images = [img for img in os.listdir(class_input_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]
        current_count = len(images)

        if current_count == 0:
            print(f"[{class_name}] Skipped (no images found).")
            continue

        needed = target_count_per_class - current_count

        print(f"[{class_name}] Current: {current_count} â†’ Need: {needed} more to reach {target_count_per_class}")

        # Copy original images to output
        for img_name in images:
            src_path = os.path.join(class_input_path, img_name)
            dst_path = os.path.join(class_output_path, img_name)
            shutil.copy2(src_path, dst_path)

        # Augment until reaching target
        i = 0
        while i < needed:
            img_name = images[i % len(images)]
            img_path = os.path.join(class_input_path, img_name)

            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                continue

            image = cv2.resize(image, (96, 96)).astype(np.float32) / 255.0
            augmented = transform(image=image)['image']
            aug_img = (augmented * 255).astype(np.uint8)

            aug_name = f"{os.path.splitext(img_name)[0]}_aug{i+1}.png"
            aug_path = os.path.join(class_output_path, aug_name)
            cv2.imwrite(aug_path, aug_img)
            i += 1

        print(f"[{class_name}] Final count: {len(os.listdir(class_output_path))}")

preprocessed_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessed_images/"
augmented_output_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessing_aug_images/"

target_count_per_class = 6539

augmented_images(preprocessed_dir, augmented_output_dir, target_count_per_class)

aug_with_original_images='/content/drive/MyDrive/Data_Visualization/Course_Project/augmented_with_orginal_images/'
augmented_images(original_images_dir, aug_with_original_images, target_count_per_class)

"""### Statistical Analysis"""

pixel_stats_analysis_aug_df=compute_pixel_intensity_stats(augmented_output_dir)
pixel_stats_analysis_aug_df

from scipy.stats import ttest_ind, f_oneway

def perform_statistical_analysis(df_stats):


    unique_classes = df_stats["Class"].unique()
    if len(unique_classes) < 2:
        print("Error: At least two classes are required for statistical analysis.")
        return

    print("Performing statistical analysis...\n")

    # Pairwise t-test for Mean Pixel Intensity
    print("Pairwise T-Tests for Mean Pixel Intensity:")
    for i in range(len(unique_classes)):
        for j in range(i + 1, len(unique_classes)):
            class_1 = unique_classes[i]
            class_2 = unique_classes[j]

            # Select data for the two classes
            data_1 = df_stats[df_stats["Class"] == class_1]["Mean_Pixel_Intensity"]
            data_2 = df_stats[df_stats["Class"] == class_2]["Mean_Pixel_Intensity"]

            # Check if classes have enough data points
            if len(data_1) < 2 or len(data_2) < 2:
                print(f"  Skipping t-test between {class_1} and {class_2}: insufficient data (less than 2 data points in one or both classes).")
                continue

            # Perform t-test
            try:
                t_stat, p_value = ttest_ind(data_1, data_2, nan_policy='omit')  # Handle NaN values gracefully
                if np.isnan(t_stat) or np.isnan(p_value):
                    print(f"  T-test between {class_1} and {class_2}: Unable to compute (NaN encountered).")
                else:
                    print(f"  T-test between {class_1} and {class_2}:")
                    print(f"    t-statistic = {t_stat:.3f}, p-value = {p_value:.3f}")
            except Exception as e:
                print(f"  Error performing t-test between {class_1} and {class_2}: {e}")

    # One-way ANOVA for Mean Pixel Intensity across all classes
    print("\nOne-way ANOVA for Mean Pixel Intensity across all classes:")
    try:
        data_groups = [df_stats[df_stats["Class"] == class_name]["Mean_Pixel_Intensity"] for class_name in unique_classes]

        # Check if all groups have sufficient data
        if any(len(group) < 2 for group in data_groups):
            print("  Skipping ANOVA: insufficient data (at least one class has fewer than 2 data points).")
            return

        f_stat, p_value = f_oneway(*data_groups)
        if np.isnan(f_stat) or np.isnan(p_value):
            print("  ANOVA: Unable to compute (NaN encountered).")
        else:
            print(f"  F-statistic = {f_stat:.3f}, p-value = {p_value:.3f}")
    except Exception as e:
        print(f"  Error performing ANOVA: {e}")

perform_statistical_analysis(pixel_stats_analysis_aug_df)

"""## Data Visualization

### Plot Bar Chart after augmentation
"""

plot_bar_image_at_each_class(aug_with_original_images)

"""### Plot Heatmap for Mutual Information"""

def plot_mi_heatmap(mi_matrix, class_names):
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        mi_matrix,
        xticklabels=class_names,
        yticklabels=class_names,
        cmap='bone_r',  # Grayscale gradient similar to the image
        annot=True,
        fmt='.0f',
        cbar=True
    )
    plt.title("Heatmap of Mutual Information Between Classes")
    plt.xlabel("Class")
    plt.ylabel("Class")
    plt.tight_layout()
    plt.show()

# # Get all class folders
class_folders = [d for d in os.listdir(original_images_dir) if os.path.isdir(os.path.join(original_images_dir, d))]

# Load one random image per class
images = {}
for class_name in class_folders:
    img, _ = load_random_image_from_class(class_name)
    images[class_name] = img

# Compute mutual information matrix
n = len(images)
mi_matrix = np.zeros((n, n))
class_names = list(images.keys())

for i in range(n):
    for j in range(n):
        mi_matrix[i, j] = calculate_mutual_information(images[class_names[i]], images[class_names[j]])
plot_mi_heatmap(mi_matrix, classes)

"""### Samples of Images Before and After Preprocssing"""

import matplotlib.pyplot as plt
import cv2
import os
import random

def visualize_before_after(original_dir, processed_dir, num_samples=5):

    class_names = [d for d in os.listdir(original_dir) if os.path.isdir(os.path.join(original_dir, d))]
    if not class_names:
        print("No classes found in original directory.")
        return

    class_name = random.choice(class_names)
    print(f"Visualizing from class: {class_name}")

    original_class_dir = os.path.join(original_dir, class_name)
    processed_class_dir = os.path.join(processed_dir, class_name)

    # Match images that exist in both original and processed folders
    common_images = list(set(os.listdir(original_class_dir)).intersection(set(os.listdir(processed_class_dir))))
    if not common_images:
        print("No matching images found between original and processed directories.")
        return

    sample_images = random.sample(common_images, min(num_samples, len(common_images)))

    # Create subplot with 2 columns (Original | Processed) and n rows
    fig, axes = plt.subplots(len(sample_images), 2, figsize=(10, 4 * len(sample_images)))

    if len(sample_images) == 1:
        axes = [axes]  # Handle single-row case

    for i, img_name in enumerate(sample_images):
        orig_path = os.path.join(original_class_dir, img_name)
        proc_path = os.path.join(processed_class_dir, img_name)

        orig_img = cv2.imread(orig_path, cv2.IMREAD_GRAYSCALE)
        proc_img = cv2.imread(proc_path, cv2.IMREAD_GRAYSCALE)

        # Original image
        axes[i][0].imshow(orig_img, cmap='gray')
        axes[i][0].set_title(f"Original - {img_name}")
        axes[i][0].axis('off')

        # Processed image
        axes[i][1].imshow(proc_img, cmap='gray')
        axes[i][1].set_title("Processed")
        axes[i][1].axis('off')

    plt.tight_layout()
    plt.show()

visualize_before_after(
    original_dir=original_images_dir,
    processed_dir=output_dir,
    num_samples=5
)

"""### Plot Grad-CAM to Show The Influence Features by Prediction"""

import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import cv2

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # convert to 1-channel
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # normalize to [-1, 1]
])

dataset = ImageFolder(root=augmented_output_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
class_names = dataset.classes

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(pretrained=True)
model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
model.fc = nn.Linear(model.fc.in_features, len(class_names))

model = model.to(device)
model.eval()

def gradcam_with_prediction(model, image_tensor, class_names, target_layer='layer4'):
    import torch
    import numpy as np
    import matplotlib.pyplot as plt
    import cv2

    model.eval()
    image_tensor = image_tensor.to(next(model.parameters()).device)

    # Forward pass and hook
    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output

    def backward_hook(module, grad_input, grad_output):
        gradients['value'] = grad_output[0]

    # Register hooks on the desired layer
    for name, module in model.named_modules():
        if name == target_layer:
            module.register_forward_hook(forward_hook)
            module.register_backward_hook(backward_hook)
            break
    else:
        raise ValueError(f"Layer '{target_layer}' not found in model.")

    # Forward + backward
    output = model(image_tensor)
    pred_class = output.argmax(dim=1).item()
    class_label = class_names[pred_class]
    score = output[0, pred_class]

    model.zero_grad()
    score.backward()

    # Grad-CAM calculation
    grad = gradients['value'][0]
    act = activations['value'][0]
    weights = grad.mean(dim=(1, 2))
    cam = torch.zeros(act.shape[1:], dtype=torch.float32).to(act.device)
    for i, w in enumerate(weights):
        cam += w * act[i]

    cam = torch.relu(cam)
    cam = cam - cam.min()
    cam = cam / cam.max() if cam.max() > 0 else cam
    cam = cam.detach().cpu().numpy()

    # Prepare input image for display
    img = image_tensor.cpu().squeeze().numpy()
    if img.ndim == 2:
        img = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)
    else:
        img = np.transpose(img, (1, 2, 0))
        img = (img * 255).astype(np.uint8)

    # Create Grad-CAM overlay
    cam_resized = cv2.resize(cam, (img.shape[1], img.shape[0]))
    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Plot results
    fig, axs = plt.subplots(1, 3, figsize=(14, 4))

    axs[0].imshow(img)
    axs[0].set_title("Input Image")
    axs[0].axis('off')

    probs = output[0].softmax(dim=0).detach().cpu().numpy()
    axs[1].barh(class_names, probs)
    axs[1].set_title("Predicted Class")
    axs[1].axvline(x=probs[pred_class], color='gray', linestyle='--')
    axs[1].invert_yaxis()

    axs[2].imshow(overlay)
    axs[2].set_title(f"Grad-CAM: {class_label}")
    axs[2].axis('off')

    plt.tight_layout()
    plt.show()

images, labels = next(iter(dataloader))
gradcam_with_prediction(model, images[0].unsqueeze(0), class_names)

"""## Predictive Analysis (Comparison Between Performance Before and After Preprocessing)"""

def load_images_from_folder(images_dir, image_size):
    images, labels = [], []
    class_names = sorted(entry for entry in os.listdir(images_dir)
                         if os.path.isdir(os.path.join(images_dir, entry)))
    class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}

    for cls_name in class_names:
        cls_path = os.path.join(images_dir, cls_name)
        for img_file in os.listdir(cls_path):
            img_path = os.path.join(cls_path, img_file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                resized_img = cv2.resize(img, image_size)
                images.append(resized_img)
                labels.append(class_to_idx[cls_name])

    return np.array(images), np.array(labels), class_names

from sklearn.model_selection import train_test_split

def image_preprocessing(images_dir, image_size):
    images, labels, class_names = load_images_from_folder(images_dir, image_size)
    images = images.astype('float32') / 255.0
    images = np.expand_dims(images, -1)
    labels = tf.keras.utils.to_categorical(labels, len(class_names))
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test, class_names

## Loading and Standard Preprocessing of Original Images

X_train, X_test, y_train, y_test, class_names= image_preprocessing(original_images_dir, (48, 48))

print('X_train Size=', X_train.shape)
print('X_test Size=', X_test.shape)
print('y_train Size=', y_train.shape)
print('y_test Size=', y_test.shape)
print('class_names Size=', len(class_names))

## Loading and Preprocessing Images after Actual Input Augmentation only

X_train_aug_with_original, X_test_aug_with_original, y_train_aug_with_original, y_test_aug_with_original,class_names_aug_with_original= image_preprocessing(aug_with_original_images, (48,48))

print('X_train Size=', X_train_aug_with_original.shape)
print('X_test Size=', X_test_aug_with_original.shape)
print('y_train Size=', y_train_aug_with_original.shape)
print('y_test Size=', y_test_aug_with_original.shape)
print('class_names Size=', len(class_names_aug_with_original))

## Loading and Preprocessing Images after Preprocessed (Removing Noise, Blur, and Upscaling)

X_train_preprocessed, X_test_preprocessed, y_train_preprocessed, y_test_preprocessed,class_names_preprocessed= image_preprocessing(output_dir, (96,96))

print('X_train Size=', X_train_preprocessed.shape)
print('X_test Size=', X_test_preprocessed.shape)
print('y_train Size=', y_train_preprocessed.shape)
print('y_test Size=', y_test_preprocessed.shape)
print('class_names Size=', len(class_names_preprocessed))

# Loading Images After Augmenatation and Preprocesssing

X_train_aug_preprocessing, X_test_aug_preprocessing, y_train_aug_preprocessing, y_test_aug_preprocessing,class_names_aug_preprocessing= image_preprocessing(augmented_output_dir, (96,96))

print('X_train Size=', X_train_aug_preprocessing.shape)
print('X_test Size=', X_test_aug_preprocessing.shape)
print('y_train Size=', y_train_aug_preprocessing.shape)
print('y_test Size=', y_test_aug_preprocessing.shape)
print('class_names Size=', len(class_names_aug_preprocessing))

"""### Build & Train the Model"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

# Define training function
def train_gaussian_nb(X_train, y_train, X_test):

    y_pred= model.predict(X_test)

    X_train_flatten = X_train.reshape(len(X_train), -1)
    X_test_flatten = X_test.reshape(len(X_test), -1)

    y_train_labels = y_train.argmax(axis=1)

    model = GaussianNB()
    model.fit(X_train_flatten, y_train_labels)

    return model, y_pred

"""### Prediction and Evaluation"""

# Define evaluation function
def evaluate_model(X_test,y_test, y_pred, class_names):

    y_test_labels = y_test.argmax(axis=1)

    accuracy = accuracy_score(y_test_labels, y_pred)
    precision= precision_score(y_test_labels, y_pred, average='weighted')
    recall= recall_score(y_test_labels, y_pred, average='weighted')
    f1= f1_score(y_test_labels, y_pred, average='weighted')

    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1 Score: {f1:.2f}")

    return y_pred

# Case 1: Prediction and Evaluation Original Images

model, y_pred= train_gaussian_nb(X_train, y_train)
evaluate_model(X_test,y_test, y_pred, class_names)

#Case2:Prediction and Evaluation Preprocessing Only

model_preprocessed, y_pred_preprocessed= train_gaussian_nb(X_train_preprocessed, y_train_preprocessed)
evaluate_model(X_test_preprocessed,y_test_preprocessed, y_pred_preprocessed, class_names_preprocessed)

# Case3: Prediction and Evaluation Augmentation of Orginal Images Only

model_aug_with_original, y_pred_aug_with_original= train_gaussian_nb(X_train_aug_with_original, y_train_aug_with_original)
evaluate_model(X_test_aug_with_original,y_test_aug_with_original, y_pred_aug_with_original, class_names_aug_with_original)

#Case4: Prediction and Evaluation Preprocessing and Augmentation

model_aug_preprocessing, y_pred_aug_preprocessing= train_gaussian_nb(X_train_aug_preprocessing, y_train_aug_preprocessing)
evaluate_model(X_test_aug_preprocessing,y_test_aug_preprocessing, y_pred_aug_preprocessing, class_names_aug_preprocessing)