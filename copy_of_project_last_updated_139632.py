# -*- coding: utf-8 -*-
"""Copy of Project_Last_Updated_139632.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mqpd3Yy9L8Xq-n4C57sY49J_SL0GCzHI

# Facial Emotion Recognition Analysis Using FER-2013 Dataset

## Import Libraries
"""

!pip install pillow

!pip install tensorflow

from google.colab import drive
import os
import random
import shutil
import cv2
import albumentations as A
import tensorflow as tf
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import seaborn as sns
from sklearn.metrics import mutual_info_score
from sklearn.metrics import silhouette_score, silhouette_samples
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, PReLU, Add, UpSampling2D, LeakyReLU, Flatten, Dense, Lambda
from tensorflow.keras.applications import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import *

"""## Load Data"""

drive.mount('/content/drive')

images_dir= '/content/drive/MyDrive/Data_Visualization/Course_Project/images/'

"""## Exploratory Data Analysis (EDA)

### Explore Labels/ Class Names
"""

classes=os.listdir(images_dir)
count_classes=len(classes)
classes

"""### Count Total Number of Images & Images at Each Class"""

def count_images(images_dir):
  total=0
  dict={}
  for directory in os.listdir(images_dir):
    c_total=len(os.listdir(images_dir+directory))
    dict[directory]=c_total
    total=total+c_total
  return total, dict

total_images,number_of_images_dict=count_images(images_dir)
print(f'Total Images: {total_images}')
print(f'Number of Images in each Class: {number_of_images_dict}')

"""### Class Balancing Test (Checking)"""

def plot_bar_image_at_each_class(images_dir):
    class_counts = {}

    # Count images in each class
    classes = os.listdir(images_dir)
    for class_name in classes:
        class_path = os.path.join(images_dir, class_name)
        if os.path.isdir(class_path):
            class_counts[class_name] = len(os.listdir(class_path))

    # Sort class_counts by count descending
    sorted_class_counts = dict(sorted(class_counts.items(), key=lambda item: item[1], reverse=True))

    classes = list(sorted_class_counts.keys())
    counts = list(sorted_class_counts.values())

    plt.figure(figsize=(8,6))
    bars = plt.bar(classes, counts, color="#34495e")

    for bar, count in zip(bars, counts):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count),
                 ha='center', va='bottom')

    plt.xlabel('Classes')
    plt.ylabel('Number of Images')
    plt.title('Number of Images per Class')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

plot_bar_image_at_each_class(images_dir)

def imbalanced_ratio(image_count_dict):
  max_count_class=max(image_count_dict.values())
  min_count_class=min(image_count_dict.values())
  ratio=max_count_class/min_count_class
  return ratio

imbalanced_ratio=imbalanced_ratio(number_of_images_dict)
print(f"Imbalanced Ratio= {imbalanced_ratio:.2f}")

"""### Pixel Intensity Analysis"""

def pixel_intensity_analysis_per_class(images_dir, classes):
    num_classes = len(classes)
    cols = 3
    rows = (num_classes + cols - 1) // cols

    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 4 * rows))
    axes = axes.flatten()
    for idx, class_name in enumerate(classes):
        pixel_intensities = []
        class_path = os.path.join(images_dir, class_name)
        class_images = os.listdir(class_path)

        for img_name in class_images:
            img_path = os.path.join(class_path, img_name)
            img = Image.open(img_path).convert('L')
            img_array = np.array(img)
            pixel_intensities.extend(img_array.flatten())

        sns.histplot(pixel_intensities, bins=256, kde=True, ax=axes[idx])
        axes[idx].set_xlabel('Pixel Intensity')
        axes[idx].set_ylabel('Frequency')
        axes[idx].set_title(f'Class: {class_name}')

    # Hide any empty subplots
    for i in range(idx + 1, len(axes)):
        fig.delaxes(axes[i])

    plt.tight_layout()
    plt.show()

pixel_intensity_analysis_per_class(images_dir, classes)

"""### Compute Mutual Information Between Two Images ( Check the Relationship)"""

def load_random_image_from_class(class_name):
    class_path = os.path.join(images_dir, class_name)
    image_files = [f for f in os.listdir(class_path) if f.endswith('.jpg') or f.endswith('.png')]
    random_file = random.choice(image_files)
    img_path = os.path.join(class_path, random_file)
    img = Image.open(img_path).convert('L')
    img = np.array(img)
    return img, random_file

class_folders = [d for d in os.listdir(images_dir) if os.path.isdir(os.path.join(images_dir, d))]

def calculate_mutual_information(img1, img2):
    img1_flat = img1.flatten()
    img2_flat = img2.flatten()
    mi = mutual_info_score(img1_flat, img2_flat)
    return mi

# Show sample of images with Mutual Information

def show_image_pairs_with_mi(num_pairs=5):
    fig, axarr = plt.subplots(num_pairs, 3, figsize=(6, num_pairs * 2.5))

    for idx in range(num_pairs):
        class1 = random.choice(class_folders)
        class2 = random.choice(class_folders)

        img1, _ = load_random_image_from_class(class1)
        img2, _ = load_random_image_from_class(class2)
        mi_value = calculate_mutual_information(img1, img2)

        # Left image
        axarr[idx, 0].imshow(img1, cmap='gray')
        axarr[idx, 0].set_title(f'{class1}', fontsize=10)
        axarr[idx, 0].axis('off')

        # Arrow with MI score above it
        axarr[idx, 1].text(0.5, 0.7, 'MI: {:.4f}'.format(mi_value), fontsize=10, ha='center', va='center')
        axarr[idx, 1].text(0.5, 0.3, 'â†’', fontsize=20, ha='center', va='center')
        axarr[idx, 1].axis('off')

        # Right image
        axarr[idx, 2].imshow(img2, cmap='gray')
        axarr[idx, 2].set_title(f'{class2}', fontsize=10)
        axarr[idx, 2].axis('off')

    plt.tight_layout(h_pad=3.0)
    plt.show()

show_image_pairs_with_mi(num_pairs=5)

"""## Data Pre-Processing

### Remove Outliers
"""

def remove_outliers(images_dir, image_size=(48, 48), iqr_multiplier=1.0, preview=False):
    for class_name in os.listdir(images_dir):
        class_dir = os.path.join(images_dir, class_name)
        if not os.path.isdir(class_dir):
            continue

        print(f"\nClass: {class_name}")
        stds = []
        image_paths = []

        # Step 1: Compute standard deviation per image
        for img_name in os.listdir(class_dir):
            if not img_name.lower().endswith(('jpg', 'jpeg', 'png')):
                continue
            img_path = os.path.join(class_dir, img_name)
            try:
                img = Image.open(img_path).convert('L').resize(image_size)
                pixel_array = np.array(img)
                std_val = pixel_array.std()
                stds.append(std_val)
                image_paths.append(img_path)
            except Exception as e:
                print(f"Error loading image {img_name}: {e}")
                continue

        if len(stds) == 0:
            print("No valid images found.")
            continue

        stds = np.array(stds)

        # Step 2: Compute IQR bounds
        Q1 = np.percentile(stds, 25)
        Q3 = np.percentile(stds, 75)
        IQR = Q3 - Q1
        lower_bound = Q1 - iqr_multiplier * IQR
        upper_bound = Q3 + iqr_multiplier * IQR

        print(f"IQR bounds (std): {lower_bound:.2f} to {upper_bound:.2f}")

        # Step 3: Identify and optionally preview outliers
        outliers = [(p, s) for p, s in zip(image_paths, stds) if s < lower_bound or s > upper_bound]
        print(f"Identified {len(outliers)} outlier(s).")

        if preview and outliers:
            fig, axes = plt.subplots(1, min(5, len(outliers)), figsize=(15, 3))
            for ax, (path, std_val) in zip(axes, outliers[:5]):
                img = Image.open(path).convert('L')
                ax.imshow(img, cmap='gray')
                ax.set_title(f"Std: {std_val:.2f}")
                ax.axis('off')
            plt.show()

        # Step 4: Delete outliers
        removed_count = 0
        for img_path, _ in outliers:
            try:
                os.remove(img_path)
                removed_count += 1
            except Exception as e:
                print(f"Failed to remove {img_path}: {e}")

        print(f"Removed {removed_count} outlier image(s) from '{class_name}'.")
    return images_dir

images_dir=remove_outliers(images_dir)
images_dir

"""### Improve Resolution Using SRGANs"""

original_images_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/images/'

augmented_output_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/augmented_images/'

"""### Remove the Noise"""

import cv2

def denoise_images(images_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Apply Non-Local Means Denoising
            denoised_img = cv2.fastNlMeansDenoising(img, None, h=10, templateWindowSize=7, searchWindowSize=21)

            # Save the denoised image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, denoised_img)

"""### Remove Blur on Images"""

def sharpen_images(images_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Apply Gaussian blur
            blurred = cv2.GaussianBlur(img, (5, 5), 0)

            # Apply Unsharp Masking
            sharpened = cv2.addWeighted(img, 1.5, blurred, -0.5, 0)

            # Save the sharpened image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, sharpened)

"""### Improve Resolution"""

def upscale_images(images_dir, output_dir, scale=2):
    os.makedirs(output_dir, exist_ok=True)
    for class_name in os.listdir(images_dir):
        class_path = os.path.join(images_dir, class_name)
        output_class_path = os.path.join(output_dir, class_name)
        os.makedirs(output_class_path, exist_ok=True)

        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            # Upscale image using bicubic interpolation
            height, width = img.shape
            upscaled = cv2.resize(img, (width * scale, height * scale), interpolation=cv2.INTER_CUBIC)

            # Save the upscaled image
            output_path = os.path.join(output_class_path, img_name)
            cv2.imwrite(output_path, upscaled)

"""### Full Image Preprocessing"""

def full_image_preprocessing_pipeline(original_dir, base_output_dir, image_size=(48, 48), scale=2, iqr_multiplier=1.5, preview_outliers=False):
    import os

    # Step 1: Remove Outliers
    print("\n Step 1: Removing outliers...")
    cleaned_dir = os.path.join(base_output_dir, 'step1_cleaned')
    shutil.copytree(original_dir, cleaned_dir, dirs_exist_ok=True)
    remove_outliers(cleaned_dir, image_size=image_size, iqr_multiplier=iqr_multiplier, preview=preview_outliers)

    # Step 2: Denoise
    print("\n Step 2: Denoising images...")
    denoised_dir = os.path.join(base_output_dir, 'step2_denoised')
    denoise_images(cleaned_dir, denoised_dir)

    # Step 3: Sharpen
    print("\n Step 3: Sharpening images...")
    sharpened_dir = os.path.join(base_output_dir, 'step3_sharpened')
    sharpen_images(denoised_dir, sharpened_dir)

    # Step 4: Upscale
    print("\n Step 4: Upscaling images...")
    final_output_dir = os.path.join(base_output_dir, 'final_output')
    upscale_images(sharpened_dir, final_output_dir, scale=scale)

    print(f"\nâœ… Preprocessing completed. Final output saved in: {final_output_dir}")
    return final_output_dir

output_dir = '/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessed_images'

full_image_preprocessing_pipeline(
    original_dir=original_images_dir,
    base_output_dir=output_dir,
    image_size=(48, 48),
    scale=2,
    iqr_multiplier=1.5,
    preview_outliers=True
)

def augment_after_preprocessing(preprocessed_dir, output_dir, target_count_per_class):

    reset_directory(output_dir)

    transform = A.Compose([
        A.HorizontalFlip(p=0.5),
        A.RandomBrightnessContrast(p=0.2),
        A.Rotate(limit=15, p=0.5),
        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),
        A.GaussNoise(p=0.2),
    ])

    for class_name in os.listdir(preprocessed_dir):
        class_input_path = os.path.join(preprocessed_dir, class_name)
        if not os.path.isdir(class_input_path):
            continue

        class_output_path = os.path.join(output_dir, class_name)
        reset_directory(class_output_path)

        images = [img for img in os.listdir(class_input_path) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]
        current_count = len(images)
        needed = target_count_per_class - current_count

        print(f"[{class_name}] Current: {current_count} â†’ Need: {needed} more to reach {target_count_per_class}")

        # Copy original images to output
        for img_name in images:
            src_path = os.path.join(class_input_path, img_name)
            dst_path = os.path.join(class_output_path, img_name)
            shutil.copy2(src_path, dst_path)

        # Augment until reaching target
        i = 0
        while i < needed:
            img_name = images[i % len(images)]
            img_path = os.path.join(class_input_path, img_name)

            image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                continue

            image = cv2.resize(image, (96, 96)).astype(np.float32) / 255.0
            augmented = transform(image=image)['image']
            aug_img = (augmented * 255).astype(np.uint8)

            aug_name = f"{os.path.splitext(img_name)[0]}_aug{i+1}.png"
            aug_path = os.path.join(class_output_path, aug_name)
            cv2.imwrite(aug_path, aug_img)
            i += 1

        print(f"[{class_name}] Final count: {len(os.listdir(class_output_path))}")

preprocessed_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessed_images/"
augmented_output_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/preprocessing_aug_images/"

target_count_per_class = 6834

augment_after_preprocessing(preprocessed_dir, augmented_output_dir, target_count_per_class)

aug_with_original_images='/content/drive/MyDrive/Data_Visualization/Course_Project/augmented_with_orginal_images/'
augment_after_preprocessing(original_images_dir, aug_with_original_images, target_count_per_class)

# --- 1. Build Generator (used only for generating HR images)
lr_shape = (48, 48, 1)
generator = build_generator(input_shape=lr_shape)

# --- 2. Load original LR images and labels
original_images_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/images"
lr_imgs, _, image_names, class_labels = load_images(original_images_dir)

# --- 3. Generate and save SRGAN output images (96x96) to disk
srgan_output_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/srgan_images"
save_srgan_generated_images(generator, lr_imgs, image_names, class_labels, srgan_output_dir)

# --- 4. Augment the saved SRGAN outputs to balance dataset
target_count = 6834  # Highest class count or desired per-class target
augmented_output_dir = "/content/drive/MyDrive/Data_Visualization/Course_Project/srgan_augmented"
augment_and_merge_images(srgan_output_dir, augmented_output_dir, target_count)

"""## Data Visualization

### Plot Bar Chart after augmentation
"""

plot_bar_image_at_each_class(aug_with_original_images)

"""### Plot Heatmap for Mutual Information"""

def plot_mi_heatmap(mi_matrix, class_names):
    plt.figure(figsize=(10, 8))
    sns.heatmap(
        mi_matrix,
        xticklabels=class_names,
        yticklabels=class_names,
        cmap='bone_r',  # Grayscale gradient similar to the image
        annot=True,
        fmt='.0f',
        cbar=True
    )
    plt.title("Heatmap of Mutual Information Between Classes")
    plt.xlabel("Class")
    plt.ylabel("Class")
    plt.tight_layout()
    plt.show()

# # Get all class folders
class_folders = [d for d in os.listdir(original_images_dir) if os.path.isdir(os.path.join(original_images_dir, d))]

# Load one random image per class
images = {}
for class_name in class_folders:
    img, _ = load_random_image_from_class(class_name)
    images[class_name] = img

# Compute mutual information matrix
n = len(images)
mi_matrix = np.zeros((n, n))
class_names = list(images.keys())

for i in range(n):
    for j in range(n):
        mi_matrix[i, j] = calculate_mutual_information(images[class_names[i]], images[class_names[j]])
plot_mi_heatmap(mi_matrix, classes)

"""### Samples of Images Before and After Preprocssing"""

import matplotlib.pyplot as plt
import cv2
import os
import random

def visualize_before_after(original_dir, processed_dir, num_samples=5):

    class_names = [d for d in os.listdir(original_dir) if os.path.isdir(os.path.join(original_dir, d))]
    if not class_names:
        print("No classes found in original directory.")
        return

    class_name = random.choice(class_names)
    print(f"Visualizing from class: {class_name}")

    original_class_dir = os.path.join(original_dir, class_name)
    processed_class_dir = os.path.join(processed_dir, class_name)

    # Match images that exist in both original and processed folders
    common_images = list(set(os.listdir(original_class_dir)).intersection(set(os.listdir(processed_class_dir))))
    if not common_images:
        print("No matching images found between original and processed directories.")
        return

    sample_images = random.sample(common_images, min(num_samples, len(common_images)))

    # Create subplot with 2 columns (Original | Processed) and n rows
    fig, axes = plt.subplots(len(sample_images), 2, figsize=(10, 4 * len(sample_images)))

    if len(sample_images) == 1:
        axes = [axes]  # Handle single-row case

    for i, img_name in enumerate(sample_images):
        orig_path = os.path.join(original_class_dir, img_name)
        proc_path = os.path.join(processed_class_dir, img_name)

        orig_img = cv2.imread(orig_path, cv2.IMREAD_GRAYSCALE)
        proc_img = cv2.imread(proc_path, cv2.IMREAD_GRAYSCALE)

        # Original image
        axes[i][0].imshow(orig_img, cmap='gray')
        axes[i][0].set_title(f"Original - {img_name}")
        axes[i][0].axis('off')

        # Processed image
        axes[i][1].imshow(proc_img, cmap='gray')
        axes[i][1].set_title("Processed")
        axes[i][1].axis('off')

    plt.tight_layout()
    plt.show()

visualize_before_after(
    original_dir=original_images_dir,
    processed_dir=output_dir,
    num_samples=5
)

"""### Plot Grad-CAM to Show The Influence Features by Prediction"""

import os
import torch
import torch.nn as nn
from torchvision import models, transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import cv2

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # convert to 1-channel
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])  # normalize to [-1, 1]
])

dataset = ImageFolder(root=augmented_output_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
class_names = dataset.classes

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = models.resnet18(pretrained=True)
model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
model.fc = nn.Linear(model.fc.in_features, len(class_names))

model = model.to(device)
model.eval()

def gradcam_with_prediction(model, image_tensor, class_names, target_layer='layer4'):
    import torch
    import numpy as np
    import matplotlib.pyplot as plt
    import cv2

    model.eval()
    image_tensor = image_tensor.to(next(model.parameters()).device)

    # Forward pass and hook
    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output

    def backward_hook(module, grad_input, grad_output):
        gradients['value'] = grad_output[0]

    # Register hooks on the desired layer
    for name, module in model.named_modules():
        if name == target_layer:
            module.register_forward_hook(forward_hook)
            module.register_backward_hook(backward_hook)
            break
    else:
        raise ValueError(f"Layer '{target_layer}' not found in model.")

    # Forward + backward
    output = model(image_tensor)
    pred_class = output.argmax(dim=1).item()
    class_label = class_names[pred_class]
    score = output[0, pred_class]

    model.zero_grad()
    score.backward()

    # Grad-CAM calculation
    grad = gradients['value'][0]
    act = activations['value'][0]
    weights = grad.mean(dim=(1, 2))
    cam = torch.zeros(act.shape[1:], dtype=torch.float32).to(act.device)
    for i, w in enumerate(weights):
        cam += w * act[i]

    cam = torch.relu(cam)
    cam = cam - cam.min()
    cam = cam / cam.max() if cam.max() > 0 else cam
    cam = cam.detach().cpu().numpy()

    # Prepare input image for display
    img = image_tensor.cpu().squeeze().numpy()
    if img.ndim == 2:
        img = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)
    else:
        img = np.transpose(img, (1, 2, 0))
        img = (img * 255).astype(np.uint8)

    # Create Grad-CAM overlay
    cam_resized = cv2.resize(cam, (img.shape[1], img.shape[0]))
    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)

    # Plot results
    fig, axs = plt.subplots(1, 3, figsize=(14, 4))

    axs[0].imshow(img)
    axs[0].set_title("Input Image")
    axs[0].axis('off')

    probs = output[0].softmax(dim=0).detach().cpu().numpy()
    axs[1].barh(class_names, probs)
    axs[1].set_title("Predicted Class")
    axs[1].axvline(x=probs[pred_class], color='gray', linestyle='--')
    axs[1].invert_yaxis()

    axs[2].imshow(overlay)
    axs[2].set_title(f"Grad-CAM: {class_label}")
    axs[2].axis('off')

    plt.tight_layout()
    plt.show()

images, labels = next(iter(dataloader))
gradcam_with_prediction(model, images[0].unsqueeze(0), class_names)

"""## Predictive Analysis (Comparison Between Performance Before and After Preprocessing)"""

def load_images_from_folder(images_dir, image_size):
    images, labels = [], []
    class_names = sorted(entry for entry in os.listdir(images_dir)
                         if os.path.isdir(os.path.join(images_dir, entry)))
    class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}

    for cls_name in class_names:
        cls_path = os.path.join(images_dir, cls_name)
        for img_file in os.listdir(cls_path):
            img_path = os.path.join(cls_path, img_file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                resized_img = cv2.resize(img, image_size)
                images.append(resized_img)
                labels.append(class_to_idx[cls_name])

    return np.array(images), np.array(labels), class_names

def image_preprocessing(images_dir, image_size):
    images, labels, class_names = load_images_from_folder(images_dir, image_size)
    images = images.astype('float32') / 255.0
    images = np.expand_dims(images, -1)
    labels = tf.keras.utils.to_categorical(labels, len(class_names))
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test, class_names

## Loading and Standard Preprocessing of Original Images

X_train, X_test, y_train, y_test, class_names= image_preprocessing(original_images_dir, (48, 48))

print('X_train Size=', X_train.shape)
print('X_test Size=', X_test.shape)
print('y_train Size=', y_train.shape)
print('y_test Size=', y_test.shape)
print('class_names Size=', len(class_names))

## Loading and Preprocessing Images after Augmentation only

X_train_aug_with_original, X_test_aug_with_original, y_train_aug_with_original, y_test_aug_with_original,class_names_aug_with_original= image_preprocessing(aug_with_original_images, (48,48))

print('X_train Size=', X_train_aug_with_original.shape)
print('X_test Size=', X_test_aug_with_original.shape)
print('y_train Size=', y_train_aug_with_original.shape)
print('y_test Size=', y_test_aug_with_original.shape)
print('class_names Size=', len(class_names_aug_with_original))

## Loading and Preprocessing Images (Removing Noise, Blur, and Upscaling)

X_train_preprocessed, X_test_preprocessed, y_train_preprocessed, y_test_preprocessed,class_names_preprocessed= image_preprocessing(output_dir, (96,96))

print('X_train Size=', X_train_preprocessed.shape)
print('X_test Size=', X_test_preprocessed.shape)
print('y_train Size=', y_train_preprocessed.shape)
print('y_test Size=', y_test_preprocessed.shape)
print('class_names Size=', len(class_names_preprocessed))

# Loading Images After Augmenatation and Preprocesssing

X_train_aug_preprocessing, X_test_aug_preprocessing, y_train_aug_preprocessing, y_test_aug_preprocessing,class_names_aug_preprocessing= image_preprocessing(augmented_output_dir, (96,96))

print('X_train Size=', X_train_aug_preprocessing.shape)
print('X_test Size=', X_test_aug_preprocessing.shape)
print('y_train Size=', y_train_aug_preprocessing.shape)
print('y_test Size=', y_test_aug_preprocessing.shape)
print('class_names Size=', len(class_names_aug_preprocessing))